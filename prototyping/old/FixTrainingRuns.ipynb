{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-09-19T09:33:01.526927860Z",
     "start_time": "2023-09-19T09:33:01.207867762Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected 1 classes in training data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|██████████| 115/115 [00:00<00:00, 429.65it/s]\n",
      "Loading dataset: 100%|██████████| 10/10 [00:00<00:00, 463.05it/s]\n"
     ]
    }
   ],
   "source": [
    "import monai\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import yaml\n",
    "import datetime\n",
    "import wandb\n",
    "from Pytorch_monai.secrets import wandbkey\n",
    "import Pytorch_monai.Model_and_transforms as MF\n",
    "import Pytorch_monai.Utils as Utils\n",
    "import json\n",
    "\n",
    "### intialize from config file\n",
    "with open('./config.yaml', 'r') as ymlfile:\n",
    "    cfg = yaml.safe_load(ymlfile)\n",
    "\n",
    "# train_label_file = cfg['training']['train_label_file']\n",
    "train_label_file = '/home/soenke/Internship/data/DATA/labels.txt'\n",
    "train_labelmap_file = cfg['training']['label_map_file']\n",
    "x_image_size = cfg['data_preparation']['image_size_x']\n",
    "y_image_size = cfg['data_preparation']['image_size_y']\n",
    "output_folder = cfg['training']['output_folder']\n",
    "batch_size = cfg['network']['batch_size']\n",
    "nb_epoch = cfg['network']['nb_epoch']\n",
    "\n",
    "## setup gpu and model name\n",
    "gpu = Utils.chooseDevice()\n",
    "now = str(datetime.datetime.now()).replace(' ', '_')\n",
    "model_name = 'DDS_model_epochs' + str(nb_epoch) + '_time_' + now\n",
    "\n",
    "##label map\n",
    "with open(train_labelmap_file) as labelmap:\n",
    "    label_map = json.load(labelmap)\n",
    "\n",
    "# load imagefilenames and onehot encoded labels\n",
    "train_image_IDs, train_image_labels, N_train_classes, extra_inputs = Utils.load_labels(train_label_file)\n",
    "print(\"Detected %d classes in training data\" % N_train_classes)\n",
    "\n",
    "#initialize monai transforms\n",
    "trainTransforms = monai.transforms.Compose(\n",
    "    [\n",
    "        monai.transforms.LoadImaged(keys=['image'],image_only=False,reader='NibabelReader',ensure_channel_first=False),\n",
    "        monai.transforms.EnsureTyped(keys=['image']),\n",
    "        monai.transforms.EnsureChannelFirstd(keys=['image'])\n",
    "    ]\n",
    ")\n",
    "valTransforms = monai.transforms.Compose(\n",
    "    [\n",
    "        monai.transforms.LoadImaged(keys=['image'],image_only=False,reader='NibabelReader',ensure_channel_first=False),\n",
    "        monai.transforms.EnsureTyped(keys=['image']),\n",
    "        monai.transforms.EnsureChannelFirstd(keys=['image'])\n",
    "    ]\n",
    ")\n",
    "\n",
    "#create data dicitionaries and data loader to which monai transforms can be applied (transforms stored in Model_and_transforms.py)\n",
    "train_data_dict = [{\"image\":image_name,\"label\":label} for image_name, label in zip(train_image_IDs,train_image_labels)]\n",
    "val_data_dict = train_data_dict[-10:]\n",
    "train_data_dict = train_data_dict[:-10] #this can be optimized to shuffle beforehand for example\n",
    "train_ds = monai.data.CacheDataset(data=train_data_dict,transform=trainTransforms,cache_rate=1,num_workers=4)\n",
    "val_ds = monai.data.CacheDataset(data=val_data_dict,transform=valTransforms,cache_rate=1,num_workers=4)\n",
    "train_loader = monai.data.DataLoader(train_ds,batch_size=1,shuffle=True,num_workers=0)\n",
    "val_loader = monai.data.DataLoader(val_ds,batch_size=1,shuffle=True,num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 1, 256, 256])"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testImg = monai.utils.first(train_loader)\n",
    "testImg['image'].shape\n",
    "#|testImg['image_meta_dict']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T09:33:01.548122698Z",
     "start_time": "2023-09-19T09:33:01.523996589Z"
    }
   },
   "id": "8287c0dde71f78ec"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "{'sizeof_hdr': tensor([348], dtype=torch.int32),\n 'extents': tensor([0], dtype=torch.int32),\n 'session_error': tensor([0], dtype=torch.int16),\n 'dim_info': tensor([0], dtype=torch.uint8),\n 'dim': tensor([[  2, 256, 256,   1,   1,   1,   1,   1]], dtype=torch.int16),\n 'intent_p1': tensor([0.]),\n 'intent_p2': tensor([0.]),\n 'intent_p3': tensor([0.]),\n 'intent_code': tensor([0], dtype=torch.int16),\n 'datatype': tensor([16], dtype=torch.int16),\n 'bitpix': tensor([32], dtype=torch.int16),\n 'slice_start': tensor([0], dtype=torch.int16),\n 'pixdim': tensor([[1., 1., 1., 1., 1., 1., 1., 1.]]),\n 'vox_offset': tensor([0.]),\n 'scl_slope': tensor([nan]),\n 'scl_inter': tensor([nan]),\n 'slice_end': tensor([0], dtype=torch.int16),\n 'slice_code': tensor([0], dtype=torch.uint8),\n 'xyzt_units': tensor([0], dtype=torch.uint8),\n 'cal_max': tensor([0.]),\n 'cal_min': tensor([0.]),\n 'slice_duration': tensor([0.]),\n 'toffset': tensor([0.]),\n 'glmax': tensor([0], dtype=torch.int32),\n 'glmin': tensor([0], dtype=torch.int32),\n 'qform_code': tensor([1], dtype=torch.int16),\n 'sform_code': tensor([1], dtype=torch.int16),\n 'quatern_b': tensor([0.]),\n 'quatern_c': tensor([0.]),\n 'quatern_d': tensor([1.]),\n 'qoffset_x': tensor([0.]),\n 'qoffset_y': tensor([239.]),\n 'qoffset_z': tensor([0.]),\n 'srow_x': tensor([[-1., -0., -0.,  0.]]),\n 'srow_y': tensor([[ -0.,  -1.,  -0., 239.]]),\n 'srow_z': tensor([[0., 0., 1., 0.]]),\n affine: tensor([[[ -1.,  -0.,  -0.,   0.],\n          [ -0.,  -1.,  -0., 239.],\n          [  0.,   0.,   1.,   0.],\n          [  0.,   0.,   0.,   1.]]], dtype=torch.float64),\n original_affine: tensor([[[ -1.,  -0.,  -0.,   0.],\n          [ -0.,  -1.,  -0., 239.],\n          [  0.,   0.,   1.,   0.],\n          [  0.,   0.,   0.,   1.]]], dtype=torch.float64),\n 'as_closest_canonical': tensor([False]),\n spatial_shape: tensor([[256, 256]], dtype=torch.int16),\n space: [RAS],\n original_channel_dim: tensor([nan], dtype=torch.float64),\n 'filename_or_obj': ['../data/NIFTI_SCLICES_test/BraTS2021_00000_t1ce___s13.nii.gz']}"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testImg['image_meta_dict']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T09:35:32.771842125Z",
     "start_time": "2023-09-19T09:35:32.682869470Z"
    }
   },
   "id": "215a9300d828c8a6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "44819d6c92aefd93"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
